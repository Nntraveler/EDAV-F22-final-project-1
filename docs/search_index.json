[["index.html", "EDAV-F22-final-project Chapter 1 Introduction", " EDAV-F22-final-project FeiFan Li, Wenqi Sun, Yusong Zhao 2022-11-01 Chapter 1 Introduction "],["proposal.html", "Chapter 2 Proposal 2.1 Research topic 2.2 Data availability", " Chapter 2 Proposal 2.1 Research topic When we travel to a city, one part of our main concern is safety. When we schedule the tour routes, we will try to avoid those dangerous areas. In this case, we need to know more information about the crimes in that city, such as crime types, occurring time, or the area with high frequency, etc. And the most effective way to acquire these pieces of information is by investigating some datasets. Hence, for this project, we found a dataset from Los Angeles’ police department, which includes all kinds of information about local crimes, like crime types, crime areas or victim info, etc. And by doing data visualization on the dataset will allow us to gain a comprehensive understanding of the dataset in a short amount of time. The main topic that we want to discuss is how should we avoid crimes when we travel to Los Angeles. For example, we may avoid certain dangerous areas or schedule our main events during the daytime. By closely analyzing the dataset, we will be able to discover more valuable information or measures to prevent these dangers. 2.2 Data availability Data source: 1. Crime Data from 2020 to Present [Los Angeles Open Data](https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8)) The data is collected in the city of Los Angeles, reflecting incidents of crime since 2020. It is transcribed from original crime reports that are typed on paper Provided by Los Angeles Police Department Owner: LAPD OpenData Data format: CSV file 591K rows * 28 columns Three types of data: string(text), numbers, date columns: Date, Weapon used, Location Status, Latitude &amp; Longitude Frequency of update: Weekly Issues: Some columns like crime codes are extremely sparse, containing lots of missing values We need to spend tons of time on data cleaning. There are many categorical columns, which require some string transformation. And some other columns carry geographical information, so we should merge these columns to extract an exact location. For some text columns, the data inside are mostly abbreviations or codes, which cannot be directly used. In this case, we need to do some research and replace these codes with suitable formats that can be understood easily. (If we had any questions about the dataset, there is a button in the original webpage, which allows us to contact the dataset owner) Plan to import: Download the csv file from the website Preprocess data for convenience : Replace columns containing spaces such as “DATE OCC” to “DATA_OCC” Remove character “-” We plan to import the csv data into MySQL database deployed on the server and visit these data through odbc package, so that it might be easier to collaborate on data. "],["data.html", "Chapter 3 Data 3.1 Sources 3.2 Cleaning / transformation 3.3 Missing value analysis", " Chapter 3 Data 3.1 Sources 3.2 Cleaning / transformation 3.3 Missing value analysis "],["results.html", "Chapter 4 Results", " Chapter 4 Results "],["interactive-component.html", "Chapter 5 Interactive component", " Chapter 5 Interactive component "],["conclusion.html", "Chapter 6 Conclusion", " Chapter 6 Conclusion "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
